# Splunk 7.x Fundamentals Part 1 eLearning 
> https://education.splunk.com/user/consume/course_pathway/b217c85e-72b4-3f06-96fa-7fc216a78823/90/82b105dc-e221-3ffe-bb66-f3e45f07d721?complete=0&amp;tab=overview
***
## MODULE 1 - Waht is Machine Data?
### 1.1 Quiz
- Machine data makes up for more than `90%` of the data accumulated by organizations.
- Machine data is always structured. `False`
- Machine data is only generated by web servers. `False`
***
## MODULE 2 - What is Splunk?
Index any data from any source. And aggregate, analyze, and get answers form the machine data.
### 2.1 5 main functions
- **Index Data**: collect data from virtually any source, inspect and label the data with a sourcetype; Break the data into single events. Add the time stamps and normalized to a consistent format. Therefore they could be searched.
- **Search & Investgate**: find events across multiple data sources, analyze and run statistics.
- **Add Knowledge**: affect how data is interpreted, give classification, add enrichment, normalize it, and save reports for future use.
- **Monitor & Alert**: proactively monitor all infrastructure in real-time, to identify issues, problems, and attacks. Create alters to monitor for specific conditions and automatically respond with a variety of actions.
- **Report & Analyze**: collect reports and visualizations into dashborads.
### 2.2 3 Processing Components
- **Indexers**: process incoming machine data, storing the results in indexes as events, and create a number of files organized in sets of directories by age.
- **Search Heads**: allow to use the Splunk Search Language, handle search requests and distribute the requests to the indexers, consolidate and enrich the results from indexers. Various tools: dashboards, reports, visualizations.
- **Forwarders**: Splunk Enterprise instances that consume data and forward it to the indexers for processing.
### 2.3 Deploying and Scaling Splunk
Splunk can be deployed in a variety of configurations.
### 2.4 Single-Instance Deployment
One instance of Splunk Enterprise handles all the functions of Splunk, including input, parsing, indexing and searching. Suitable for proof of concept, personal use, learning and serve the needs of small department-sized environments.
In a production environment as our usage scales, we would need to start splitting some of this functionlity across multiple specialized instances. Search heads and indexers can also be clustered.
### 2.5 Quiz
- Search requests are processed by the `Indexers`.
- Which function is not a part of a single instance deployment? `Clustering`
- A single-instance deployment of Splunk Enterprise handles: `Indexing / Searching / Parsing / Input`
- Which of these is not a main component of Splunk? `Compress and archive`
- In most Splunk deployments, `Forwarders` serve as the primary way data is supplied for indexing.
***
## MODULE 3 - Installing Splunk
### 3.1 Plantform
Linux / Windows / OSX / Splunk Cloud / Apps and Roles.
### 3.2 Lab - Splunk Fundamentals 1 Lab Exercisesy
[SplunkFundamentals1_module3.pdf](https://github.com/Steve1516/Splunk/files/7127327/SplunkFundamentals1_module3.pdf)
### 3.3 Quiz
- This role will only see their own knowledge objects and those that have been shared with them.  `user`
- The password for a newly installed Splunk instance is: `Created when you install Splunk Enterprise.`
- What are the three main default roles in Splunk Enterprise? `Admin \ User \ Power`
- You can launch and manage apps from the home app. `True`
- `Roles` define what users can do in Splunk.
***
## MODULE 4 - Getting Data In
### 4.1 Types of Data Input
**Add data**: Networking / OperatingSystem / Security
**Upload**: Local log files
**Monitor**: Files&Directories / HTTP Events Collector / TCP/UDP / Scripts(API,service,database) / Win includeï¼šEvent log / File System Changes / Active Directory / Network Information from local or remote machines.
**Forward**: In most production environments, forwarders will be used as main source of data input.
### 4.2 Using the Data Upload Input Option
**Upload**: suitable for files which will never update.
- If Splunk recognizes the data, it'll assign it a pre-trained source type.
- The `APP` context setting is something to be aware of in Splunk, the section you made will tell Splunk which app to apply this sourcetype to(Instrumentation / Monitoring Console / Search&Reporting / System).
- The `Host` should be the name of the machine from which these events originate.
**Indexes**: are directories where the data will be stored.
